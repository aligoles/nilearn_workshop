{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nNeuroVault meta-analysis of stop-go paradigm studies.\n=====================================================\n\nThis example shows how to download statistical maps from\nNeuroVault\n\nSee :func:`nilearn.datasets.fetch_neurovault_ids`\ndocumentation for more details.\n\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Author: Ben Cipollini\n# License: BSD\nimport scipy\n\nfrom nilearn.datasets import fetch_neurovault_ids\nfrom nilearn import plotting\nfrom nilearn.image import new_img_like, load_img, math_img"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Fetch images for \"successful stop minus go\"-like protocols.\n-----------------------------------------------------------\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# These are the images we are interested in,\n# in order to save time we specify their ids explicitly.\nstop_go_image_ids = (151, 3041, 3042, 2676, 2675, 2818, 2834)\n\n# These ids were determined by querying neurovault like this:\n\n# from nilearn.datasets import fetch_neurovault, neurovault\n\n# nv_data = fetch_neurovault(\n#     max_images=7,\n#     cognitive_paradigm_cogatlas=neurovault.Contains('stop signal'),\n#     contrast_definition=neurovault.Contains('succ', 'stop', 'go'),\n#     map_type='T map')\n\n# print([meta['id'] for meta in nv_data['images_meta']])\n\n\nnv_data = fetch_neurovault_ids(image_ids=stop_go_image_ids)\n\nimages_meta = nv_data['images_meta']\ncollections = nv_data['collections_meta']"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Visualize the data\n------------------\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "print('\\nplotting glass brain for collected images\\n')\n\nfor im in images_meta:\n    plotting.plot_glass_brain(\n        im['absolute_path'],\n        title='image {0}: {1}'.format(im['id'], im['contrast_definition']))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Compute statistics\n------------------\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "def t_to_z(t_scores, deg_of_freedom):\n    p_values = scipy.stats.t.sf(t_scores, df=deg_of_freedom)\n    z_values = scipy.stats.norm.isf(p_values)\n    return z_values\n\n\n# Compute z values\nmean_maps = []\nz_imgs = []\ncurrent_collection = None\n\nprint(\"\\nComputing maps...\")\n\n\n# convert t to z for all images\nfor this_meta in images_meta:\n    if this_meta['collection_id'] != current_collection:\n        print(\"\\n\\nCollection {0}:\".format(this_meta['id']))\n        current_collection = this_meta['collection_id']\n\n    # Load and validate the downloaded image.\n    t_img = load_img(this_meta['absolute_path'])\n    deg_of_freedom = this_meta['number_of_subjects'] - 2\n    print(\"     Image {1}: degrees of freedom: {2}\".format(\n        \"\", this_meta['id'], deg_of_freedom))\n\n    # Convert data, create new image.\n    z_img = new_img_like(\n        t_img, t_to_z(t_img.get_data(), deg_of_freedom=deg_of_freedom))\n\n    z_imgs.append(z_img)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Plot the combined z maps\n------------------------\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "cut_coords = [-15, -8, 6, 30, 46, 62]\nmeta_analysis_img = math_img(\n    'np.sum(z_imgs, axis=3) / np.sqrt(z_imgs.shape[3])',\n    z_imgs=z_imgs)\n\nplotting.plot_stat_map(meta_analysis_img, display_mode='z', threshold=6,\n                       cut_coords=cut_coords, vmax=12)\n\n\nplotting.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.13", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}